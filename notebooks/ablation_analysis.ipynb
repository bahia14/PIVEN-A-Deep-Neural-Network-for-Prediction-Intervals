{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an ensemble of piven regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_regressors = 10\n",
    "n = test_y.shape[0]\n",
    "y_pred_out = np.zeros((n, n_regressors))\n",
    "y_pred_pi_low = np.zeros((n, n_regressors))\n",
    "y_pred_pi_high = np.zeros((n, n_regressors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function\n",
    "def make_model():\n",
    "    # Put model in pipeline\n",
    "    model = PivenKerasRegressor(build_fn=piven_model, \n",
    "                              input_dim=train_x.shape[-1], \n",
    "                              dense_units=(32,16), \n",
    "                              dropout_rate=(0.0,0.09),\n",
    "                              lambda_=22.28,\n",
    "                              lr= 0.000428)\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocess\", StandardScaler()),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    # Finally, normalize the output target\n",
    "    model_ttr = PivenTransformedTargetRegressor(\n",
    "        regressor=pipeline,\n",
    "        transformer=StandardScaler()\n",
    "    )\n",
    "    return model_ttr\n",
    "\n",
    "# Back-transform the predictions and PIs\n",
    "def back_transform(x, max_train):\n",
    "    xexp = np.exp(x)\n",
    "    return max_train + 1 - xexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=2, verbose=1,\n",
    "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.00001\n",
    ")\n",
    "# Fit\n",
    "for i in range(n_regressors):\n",
    "    print(f\"Fitting model {i+1}\")  \n",
    "    model_ttr = make_model()\n",
    "    h = model_ttr.fit(train_x, train_y_transformed, model__epochs=25, \n",
    "                      model__validation_split=0.2, model__batch_size=64,\n",
    "                      model__callbacks=[early_stop, reduce_lr])\n",
    "    ypred, y_pi_low, y_pi_high = model_ttr.predict(test_x, \n",
    "                                                   return_prediction_intervals=True)\n",
    "\n",
    "    y_pred_out[:,i] = back_transform(ypred, max_out_train)\n",
    "    # Need to reverse the bounds\n",
    "    y_pred_pi_low[:,i] = back_transform(y_pi_high, max_out_train)\n",
    "    y_pred_pi_high[:,i] = back_transform(y_pi_low, max_out_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y_pred.npy\", y_pred_out)\n",
    "np.save(\"y_pred_pi_low.npy\", y_pred_pi_low)\n",
    "np.save(\"y_pred_pi_high.npy\", y_pred_pi_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.mean(y_pred_out, axis=1)\n",
    "y_pi_low = np.mean(y_pred_pi_low, axis=1)\n",
    "y_pi_high = np.mean(y_pred_pi_high, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sort = np.argsort(test_y)\n",
    "plt.fill_betweenx(\n",
    "    test_y[idx_sort],\n",
    "    y_pi_low[idx_sort],\n",
    "    y_pi_high[idx_sort],\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.scatter(y_pred[idx_sort], test_y[idx_sort], c=\"r\", alpha=0.2)\n",
    "plt.xlim(1900, 2015)\n",
    "plt.title(\"Predicted versus true release years\")\n",
    "plt.xlabel(\"Predicted release year\")\n",
    "plt.ylabel(\"True release year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sort = np.argsort(test_y)\n",
    "for idx in range(y_pred_out.shape[1]):\n",
    "    plt.plot(y_pred_pi_low[idx_sort, idx], test_y[idx_sort], alpha=0.6)\n",
    "    plt.plot(y_pred_pi_high[idx_sort, idx], test_y[idx_sort], alpha=0.6)\n",
    "plt.xlim(1860, 2015)\n",
    "plt.title(\"Predicted versus true release years\")\n",
    "plt.xlabel(\"Predicted release year\")\n",
    "plt.ylabel(\"True release year\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pivenregressor)",
   "language": "python",
   "name": "pivenregressor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
