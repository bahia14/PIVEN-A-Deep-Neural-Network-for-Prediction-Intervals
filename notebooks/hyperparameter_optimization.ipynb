{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def back_transform(x, max_train):\n",
    "    xexp = np.exp(x)\n",
    "    return max_train + 1 - xexp\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=2, verbose=0,\n",
    "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.00001\n",
    ")\n",
    "\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    lambda_ = trial.suggest_float(\"lambda_\", 22.0, 28.0)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 0.001)\n",
    "    dropout_rate_l1 = trial.suggest_uniform(\"dropout_rate_l1\", 0.0, 0.5)\n",
    "    dropout_rate_l2 = trial.suggest_uniform(\"dropout_rate_l2\", 0.0, 0.5)\n",
    "    layer_size = trial.suggest_categorical(\"layer_size\", \n",
    "                                           [\"32+16\", \"64+32\", \n",
    "                                            \"128+64\", \"128+128\"],\n",
    "                                          )\n",
    "    layer_size = tuple([int(ls) for ls in layer_size.split(\"+\")])\n",
    "    seed = trial.suggest_int(\"seed\", 162, 9999999)\n",
    "    np.random.seed(seed)\n",
    "    # Split train from test data\n",
    "    x_ind = [*range(train_x.shape[0])]\n",
    "    np.random.shuffle(x_ind)\n",
    "    train_x_trial, val_x_trial = train_x[:420000, :].copy(), train_x[420000:, :].copy()\n",
    "    train_y_trial, val_y_trial = train_y[:420000].copy(), train_y[420000:].copy()\n",
    "    max_train_out = np.max(train_y_trial)\n",
    "    # Transform\n",
    "    train_y_trial_transformed = reflect_and_log(train_y_trial, max_train_out)\n",
    "    val_y_trial_transformed = reflect_and_log(val_y_trial, max_train_out)\n",
    "    # Instantiate model\n",
    "    model = PivenKerasRegressor(build_fn=piven_model, \n",
    "                              input_dim=train_x_trial.shape[-1], \n",
    "                              dense_units=layer_size, \n",
    "                              dropout_rate=(dropout_rate_l1, dropout_rate_l2),\n",
    "                              lambda_=lambda_,\n",
    "                              lr=lr)\n",
    "    # Put model in pipeline\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocess\", StandardScaler()),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    model_ttr = PivenTransformedTargetRegressor(regressor=pipeline,\n",
    "                                                transformer=StandardScaler())\n",
    "    # Fit\n",
    "    model_ttr.fit(train_x_trial, train_y_trial_transformed, model__epochs=25, \n",
    "                  model__validation_split=0.1, model__batch_size=64,\n",
    "                  model__verbose=False, model__callbacks=[early_stop, reduce_lr])\n",
    "    y_pred, y_pred_pi_low, y_pred_pi_high = model_ttr.predict(val_x_trial, return_prediction_intervals=True)\n",
    "    # Back-transform the predictions and PIs\n",
    "    y_pred = back_transform(y_pred, max_train_out)\n",
    "    y_pi_low = back_transform(y_pred_pi_high, max_train_out)\n",
    "    y_pi_high = back_transform(y_pred_pi_low, max_train_out)\n",
    "    # Compute metrics\n",
    "    cov_trial = coverage(val_y_trial, y_pi_low, y_pi_high)\n",
    "    piw_trial = pi_width(y_pi_low, y_pi_high)\n",
    "    loss_trial = piven_loss_numpy(val_y_trial, y_pred, y_pi_low, y_pi_high, lambda_, 160.0, 0.05)\n",
    "    # Set metrics\n",
    "    trial.set_user_attr(\"coverage\", float(cov_trial))\n",
    "    trial.set_user_attr(\"pi_width\", float(piw_trial))\n",
    "    # Return model loss\n",
    "    return loss_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = optuna.create_study(direction=\"minimize\",\n",
    "                                 study_name=\"piven_year_msd\",\n",
    "                                 storage='sqlite:///data/experiment_results.db',\n",
    "                                 load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.optimize(objective, n_trials=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (pivenregressor)",
   "language": "python",
   "name": "pycharm-b9238b0d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
